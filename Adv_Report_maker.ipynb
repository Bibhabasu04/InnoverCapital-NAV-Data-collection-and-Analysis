{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5ef4a51-1787-4231-90f3-c5a8a5f87d6c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start: Import Libraries\n",
    "# ---------------------------\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer\n",
    "from reportlab.lib.styles import getSampleStyleSheet"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ba814fc-a215-4d13-9dcc-5e0c5bfdf6da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# Part 0: Latest Data Insertion\n",
    "# ---------------------------\n",
    "def append_value_with_date(file1_path, file2_path, sheet1_name, row1_number, sheet2_name, row2_number):\n",
    "    \"\"\"\n",
    "    Appends the last non-empty cell (as text) from a specified row of file1 to the next available cell \n",
    "    in a specified row of file2, and writes today's date (dd/mm/yyyy) as text in the cell immediately above.\n",
    "    \n",
    "    Parameters:\n",
    "        file1_path (str): Path to the first Excel file.\n",
    "        file2_path (str): Path to the second Excel file.\n",
    "        sheet1_name (str): Sheet name in the first file to read from.\n",
    "        row1_number (int): Row number in the first file to look for the last value.\n",
    "        sheet2_name (str): Sheet name in the second file to write to.\n",
    "        row2_number (int): Row number in the second file where the value is to be appended.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open file1 and get the specified sheet.\n",
    "    wb1 = load_workbook(file1_path, data_only=True)\n",
    "    if sheet1_name not in wb1.sheetnames:\n",
    "        raise ValueError(f\"Sheet '{sheet1_name}' not found in {file1_path}.\")\n",
    "    ws1 = wb1[sheet1_name]\n",
    "    \n",
    "    # Retrieve all cells in the specified row of file1.\n",
    "    row_cells = ws1[row1_number]\n",
    "    last_value = None\n",
    "    for cell in row_cells:\n",
    "        if cell.value is not None:\n",
    "            last_value = cell.value  # This overwrites until the last non-empty cell is reached.\n",
    "    \n",
    "    if last_value is None:\n",
    "        raise ValueError(f\"No value found in row {row1_number} of sheet '{sheet1_name}' in {file1_path}.\")\n",
    "    \n",
    "    # Open file2 and get the specified sheet.\n",
    "    wb2 = load_workbook(file2_path)\n",
    "    if sheet2_name not in wb2.sheetnames:\n",
    "        raise ValueError(f\"Sheet '{sheet2_name}' not found in {file2_path}.\")\n",
    "    ws2 = wb2[sheet2_name]\n",
    "    \n",
    "    # Find the last non-empty cell in the specified row of file2.\n",
    "    row_cells_file2 = ws2[row2_number]\n",
    "    last_col_index = 0\n",
    "    for cell in row_cells_file2:\n",
    "        if cell.value is not None:\n",
    "            if cell.column > last_col_index:\n",
    "                last_col_index = cell.column\n",
    "    \n",
    "    # The new value will be written in the next column.\n",
    "    new_col = last_col_index + 1\n",
    "    \n",
    "    # Write the retrieved value (as text) into the target cell.\n",
    "    ws2.cell(row=row2_number, column=new_col, value=str(last_value))\n",
    "    \n",
    "    # Write today's date (dd/mm/yyyy) in the cell immediately above the newly written value.\n",
    "    if row2_number > 1:\n",
    "        today_str = (datetime.today() - timedelta(days=1)).strftime(\"%d/%m/%Y\")\n",
    "        ws2.cell(row=row2_number - 1, column=new_col, value=today_str)\n",
    "    else:\n",
    "        print(\"Warning: Target row is 1. Cannot insert date in the row above.\")\n",
    "    \n",
    "    # Save the modified file2.\n",
    "    wb2.save(file2_path)\n",
    "    # print(f\"Appended value '{last_value}' from {file1_path} to {file2_path} (Sheet: '{sheet2_name}', Row: {row2_number}).\")\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual file paths, sheet names, and row numbers.\n",
    "    file1 = \"D:/Innover/Insurance NAV.xlsx\"\n",
    "    file2 = \"D:/Innover/Advanced_funds.xlsx\"\n",
    "    row1_list = [[4, 3, 2, 26, 37, 10, 21, 13, 13, 5, 8, 9, 11, 12, 55], [27, 38], [35, 21]] \n",
    "    sheet1_list = [[\"HDFC\",\"HDFC\", \"HDFC\", \"ICICI\", \"ICICI\", \"Kotak\", \"Maxlife\",\n",
    "                    \"Birla\", \"Tata\", \"SBI\", \"SBI\", \"SBI\", \"Bajaj\", \"PNB\", \"LIC\"],\n",
    "                   [\"ICICI\", \"SBI\"],\n",
    "                    [\"ICICI\", \"Kotak\"]] \n",
    "    sheet2_list = [\"Medium to Long Duration Funds\", \"Money Market Funds\", \"Group Funds\"]\n",
    "    \n",
    "    row2_list = [[3,5,7,9,11,13,15,17,19,21,23,25,27,29,31], [3,5], [3,5]]\n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        sheet2 = sheet2_list[i]\n",
    "        for j in range(len(row2_list[i])):\n",
    "            row2 = row2_list[i][j] + 1\n",
    "            row1 = row1_list[i][j]\n",
    "            sheet1 = sheet1_list[i][j]\n",
    "            \n",
    "            append_value_with_date(file1, file2, sheet1, row1, sheet2, row2)\n",
    "            count += 1\n",
    "            print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad5aa923-93ca-4e70-bdee-c83fa5879911",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Part 1: Data Processing Functions\n",
    "# ---------------------------\n",
    "def process_excel_file(file_path):\n",
    "    \"\"\"\n",
    "    Reads an Excel file with three sheets and splits each sheet into datasets.\n",
    "    \n",
    "    For each sheet:\n",
    "      - Starting from the 3rd row (index 2), every two consecutive rows form a dataset.\n",
    "      - For each dataset:\n",
    "          - The data (to be used in return calculations) are taken from the 3rd column onward.\n",
    "          - The first two columns of the first row in the pair are extracted as names.\n",
    "    \n",
    "    Note: The Excel file is assumed to have all data in text format.\n",
    "    \n",
    "    Returns:\n",
    "        A dictionary mapping sheet names to a list of dataset dictionaries. Each dataset dict has:\n",
    "          - 'name1': Insurer name.\n",
    "          - 'name2': Fund Name.\n",
    "          - 'data': A 2-row DataFrame where:\n",
    "                    - Row 0 contains date strings in dd/mm/yyyy format.\n",
    "                    - Row 1 contains numeric values as text.\n",
    "    \"\"\"\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    sheets_data = {}\n",
    "    \n",
    "    for sheet_name in xls.sheet_names:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, header=None, dtype=str)\n",
    "        datasets = []\n",
    "        \n",
    "        # Starting from 3rd row (index 2), take pairs of rows.\n",
    "        for i in range(2, len(df), 2):\n",
    "            if i + 1 < len(df):\n",
    "                name1 = df.iloc[i, 0]\n",
    "                name2 = df.iloc[i, 1]\n",
    "                data = df.iloc[i:i+2, 2:]\n",
    "                datasets.append({\n",
    "                    'name1': name1,\n",
    "                    'name2': name2,\n",
    "                    'data': data\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: Row {i+1} in sheet '{sheet_name}' does not have a pair; skipping.\")\n",
    "        \n",
    "        sheets_data[sheet_name] = datasets\n",
    "    \n",
    "    return sheets_data\n",
    "\n",
    "# def get_closest_data_point(dates, values, target_date):\n",
    "#     \"\"\"\n",
    "#     Given lists of dates (as datetime objects) and corresponding values, find the data point\n",
    "#     (i.e. date and value) where the date is the largest date that is less than or equal to target_date.\n",
    "    \n",
    "#     Returns:\n",
    "#         (closest_date, corresponding_value, index)\n",
    "    \n",
    "#     Raises:\n",
    "#         ValueError if no date in the list is <= target_date.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     candidates = [(i, dt) for i, dt in enumerate(dates) if dt <= target_date]\n",
    "#     print(len(dates), len(candidates))\n",
    "#     if not candidates:\n",
    "#         raise ValueError(\"No date found that is less than or equal to the target date.\")\n",
    "#     candidate_idx, candidate_date = max(candidates, key=lambda x: x[1])\n",
    "#     print(max(candidates, key=lambda x: x[1]))\n",
    "#     candidate_value = values[candidate_idx]\n",
    "#     print(candidate_date, candidate_value, candidate_idx)\n",
    "#     return candidate_date, candidate_value, candidate_idx\n",
    "\n",
    "def get_closest_data_point(dates, values, target_date):\n",
    "    \"\"\"\n",
    "    Given lists of dates (as datetime objects) and corresponding values,\n",
    "    this function sorts the data by date and then finds the data point (i.e. date and value)\n",
    "    where the date is the largest that is less than or equal to target_date.\n",
    "    \n",
    "    Returns:\n",
    "        (closest_date, corresponding_value, original_index)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError if no date in the list is <= target_date.\n",
    "    \"\"\"\n",
    "    # Create a list of tuples: (original_index, date, value)\n",
    "    paired = list(zip(range(len(dates)), dates, values))\n",
    "    # Sort the list by date (ascending)\n",
    "    paired_sorted = sorted(paired, key=lambda x: x[1])\n",
    "    \n",
    "    # Filter the sorted pairs for those with date <= target_date\n",
    "    sorted_candidates = [ (i, dt, val) for i, dt, val in paired_sorted if dt <= target_date ]\n",
    "    \n",
    "    if not sorted_candidates:\n",
    "        raise ValueError(\"No date found that is less than or equal to the target date.\")\n",
    "    \n",
    "    # The candidate we want is the last one in the sorted order.\n",
    "    candidate_idx, candidate_date, candidate_value = sorted_candidates[-1]\n",
    "    \n",
    "    # For debugging, if you want to see the position in the sorted candidates list:\n",
    "    # candidate_sorted_position = len(sorted_candidates) - 1\n",
    "    # print(\"Total dates:\", len(dates), \"Candidates in sorted order:\", len(sorted_candidates),\n",
    "    #       \"Candidate sorted position:\", candidate_sorted_position)\n",
    "    \n",
    "    return candidate_date, candidate_value, candidate_idx\n",
    "\n",
    "\n",
    "def calculate_returns(data):\n",
    "    \"\"\"\n",
    "    Given a 2-row DataFrame (row 0: dates as dd/mm/yyyy strings, row 1: numeric values as text),\n",
    "    compute various return metrics using the formula:\n",
    "    \n",
    "        (current value - previous value) / previous value * (365 * 100) / days_difference\n",
    "    \n",
    "    The computed return is rounded to two decimals.\n",
    "    \n",
    "    Returns a dictionary with keys:\n",
    "      'daily', 'weekly', 'monthly', '3-monthly', '6-monthly', 'FYTD', and 'latest_NAV'.\n",
    "    Note: The MTD return calculation has been commented out.\n",
    "    \"\"\"\n",
    "    date_strs = data.iloc[0].tolist()\n",
    "    value_strs = data.iloc[1].tolist()\n",
    "    \n",
    "    parsed_dates = []\n",
    "    parsed_values = []\n",
    "    \n",
    "    # Process each column; skip if date is missing or \"nan\"\n",
    "    for dt, val in zip(date_strs, value_strs):\n",
    "        dt_str = str(dt).strip() if dt is not None else \"\"\n",
    "        if dt_str == \"\" or dt_str.lower() == \"nan\":\n",
    "            continue\n",
    "        try:\n",
    "            parsed_date = datetime.strptime(dt_str, \"%d/%m/%Y\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error parsing date '{dt_str}': {e}\")\n",
    "        try:\n",
    "            num_val = float(val)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error converting value '{val}' to float: {e}\")\n",
    "        parsed_dates.append(parsed_date)\n",
    "        parsed_values.append(num_val)\n",
    "\n",
    "    if len(parsed_dates) < 2:\n",
    "        raise ValueError(\"Not enough valid data points to compute returns.\")\n",
    "    \n",
    "    # The current (latest) data point.\n",
    "    current_date = parsed_dates[-1]\n",
    "    current_value = parsed_values[-1]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    def compute_return(prev_value, days_diff):\n",
    "        if prev_value == 0 or days_diff == 0:\n",
    "            return None\n",
    "        ret = ((current_value - prev_value) / prev_value) * (365 * 100) / days_diff\n",
    "        return round(ret, 2)\n",
    "    \n",
    "    # Daily return: use the immediate preceding valid data point.\n",
    "    prev_date_daily = parsed_dates[-2]\n",
    "    prev_value_daily = parsed_values[-2]\n",
    "    d_1 = (current_date - prev_date_daily).days\n",
    "    daily_return = compute_return(prev_value_daily, d_1)\n",
    "    results['daily'] = {\"d_1\": d_1, \"return\": daily_return}\n",
    "    \n",
    "    # Weekly return: target = current_date - 7 days.\n",
    "    required_weekly = current_date - timedelta(days=7)\n",
    "    try:\n",
    "        prev_date_weekly, prev_value_weekly, _ = get_closest_data_point(parsed_dates, parsed_values, required_weekly)\n",
    "        d_7 = (current_date - prev_date_weekly).days\n",
    "        weekly_return = compute_return(prev_value_weekly, d_7)\n",
    "    except ValueError:\n",
    "        d_7 = None\n",
    "        weekly_return = None\n",
    "    results['weekly'] = {\"d_7\": d_7, \"return\": weekly_return}\n",
    "    \n",
    "    # 1-month return: target = current_date - 1 month.\n",
    "    required_monthly = current_date - relativedelta(months=1)\n",
    "    try:\n",
    "        prev_date_monthly, prev_value_monthly, _ = get_closest_data_point(parsed_dates, parsed_values, required_monthly)\n",
    "        d_m = (current_date - prev_date_monthly).days\n",
    "        monthly_return = compute_return(prev_value_monthly, d_m)\n",
    "    except ValueError:\n",
    "        d_m = None\n",
    "        monthly_return = None\n",
    "    results['monthly'] = {\"d_m\": d_m, \"return\": monthly_return}\n",
    "    \n",
    "    # 3-month return: target = current_date - 3 months.\n",
    "    required_3m = current_date - relativedelta(months=3)\n",
    "    try:\n",
    "        prev_date_3m, prev_value_3m, _ = get_closest_data_point(parsed_dates, parsed_values, required_3m)\n",
    "        d_3m = (current_date - prev_date_3m).days\n",
    "        ret_3m = compute_return(prev_value_3m, d_3m)\n",
    "    except ValueError:\n",
    "        d_3m = None\n",
    "        ret_3m = None\n",
    "    results['3-monthly'] = {\"d_3m\": d_3m, \"return\": ret_3m}\n",
    "    \n",
    "    # 6-month return: target = current_date - 6 months.\n",
    "    required_6m = current_date - relativedelta(months=6)\n",
    "    try:\n",
    "        prev_date_6m, prev_value_6m, _ = get_closest_data_point(parsed_dates, parsed_values, required_6m)\n",
    "        d_6m = (current_date - prev_date_6m).days\n",
    "        ret_6m = compute_return(prev_value_6m, d_6m)\n",
    "    except ValueError:\n",
    "        d_6m = None\n",
    "        ret_6m = None\n",
    "    results['6-monthly'] = {\"d_6m\": d_6m, \"return\": ret_6m}\n",
    "    \n",
    "    # FYTD return: fixed target date, here 01/04/2024.\n",
    "    required_fytd = datetime.strptime(\"01/04/2025\", \"%d/%m/%Y\")\n",
    "    try:\n",
    "        prev_date_fytd, prev_value_fytd, _ = get_closest_data_point(parsed_dates, parsed_values, required_fytd)\n",
    "        d_y = (current_date - prev_date_fytd).days\n",
    "        fytd_return = compute_return(prev_value_fytd, d_y)\n",
    "    except ValueError:\n",
    "        d_y = None\n",
    "        fytd_return = None\n",
    "    results['FYTD'] = {\"d_y\": d_y, \"return\": fytd_return}\n",
    "    \n",
    "    # # MTD return calculation is commented out.\n",
    "    # required_mtd = current_date.replace(day=1)\n",
    "    # try:\n",
    "    #     prev_date_mtd, prev_value_mtd, _ = get_closest_data_point(parsed_dates, parsed_values, required_mtd)\n",
    "    #     d_mtd = (current_date - prev_date_mtd).days\n",
    "    #     mtd_return = compute_return(prev_value_mtd, d_mtd)\n",
    "    # except ValueError:\n",
    "    #     d_mtd = None\n",
    "    #     mtd_return = None\n",
    "    # results['MTD'] = {\"d_mtd\": d_mtd, \"return\": mtd_return}\n",
    "    \n",
    "    # Store the current (latest) value (Latest NAV).\n",
    "    results['latest_NAV'] = current_value\n",
    "    # print(results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a479854-4937-4581-a292-160d8aad439d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Part 2: PDF Report Generation\n",
    "# ---------------------------\n",
    "def create_pdf_report(sheets_datasets, output_pdf, date):\n",
    "    \"\"\"\n",
    "    Creates a PDF report with a bold title and one table per sheet.\n",
    "    \n",
    "    Each table has 9 columns:\n",
    "      \"Insurer\", \"Fund Name\", \"Latest NAV\", \"Daily return\", \"Weekly return\", \n",
    "      \"1-month return\", \"3-month return\", \"6-month return\", \"FYTD return\".\n",
    "      \n",
    "    The table rows are sorted by Daily return (largest to smallest).\n",
    "    At the end of the PDF, two notes are added:\n",
    "      *Axis Maxlife NAV values are rounded off to 2 digits after decimal\n",
    "      **All returns are calculated as percentage(%)\n",
    "    \"\"\"\n",
    "    sheet_tables = {}\n",
    "    \n",
    "    # Build table data for each sheet.\n",
    "    for sheet_name, datasets in sheets_datasets.items():\n",
    "        rows = []\n",
    "        for dataset in datasets:\n",
    "            insurer = dataset['name1']\n",
    "            fund_name = dataset['name2']\n",
    "            if insurer not in exclude_fund:\n",
    "                print(insurer, fund_name)\n",
    "                try:\n",
    "                    ret = calculate_returns(dataset['data'])\n",
    "                    daily = ret.get('daily', {}).get('return', None)\n",
    "                    weekly = ret.get('weekly', {}).get('return', None)\n",
    "                    monthly = ret.get('monthly', {}).get('return', None)\n",
    "                    three_monthly = ret.get('3-monthly', {}).get('return', None)\n",
    "                    six_monthly = ret.get('6-monthly', {}).get('return', None)\n",
    "                    fytd = ret.get('FYTD', {}).get('return', None)\n",
    "                    latest_nav = ret.get('latest_NAV', None)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue  # Skip dataset if returns cannot be computed.\n",
    "                \n",
    "                # New row: Insert Latest NAV between Fund Name and Daily return.\n",
    "                rows.append([insurer, fund_name, latest_nav, daily, weekly, monthly, three_monthly, six_monthly, fytd])\n",
    "    \n",
    "        # Sort rows by Daily return (index 3) descending.\n",
    "        rows_sorted = sorted(rows, key=lambda x: x[3] if x[3] is not None else -float('inf'), reverse=True)\n",
    "        sheet_tables[sheet_name] = rows_sorted\n",
    "\n",
    "    # Setup the PDF document.\n",
    "    doc = SimpleDocTemplate(output_pdf, pagesize=A4,\n",
    "                            leftMargin=36, rightMargin=36, topMargin=36, bottomMargin=36)\n",
    "    elements = []\n",
    "    styles = getSampleStyleSheet()\n",
    "    \n",
    "    # Title: Bold title with current date.\n",
    "    title_text = \"Life Insurance Fund Performance Report for NAV dated \" + date\n",
    "    title_paragraph = Paragraph(\"<b>\" + title_text + \"</b>\", styles['Title'])\n",
    "    elements.append(title_paragraph)\n",
    "    elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Define headers with updated names.\n",
    "    headers = [\"Insurer\", \"Fund Name\", \"Latest NAV\", \"Daily return\", \"Weekly return\", \n",
    "               \"1-month return\", \"3-month return\", \"6-month return\", \"FYTD return\"]\n",
    "    \n",
    "    # Define fixed column widths (adjust as needed).\n",
    "    col_widths = [60, 80, 40, 50, 50, 50, 50, 50, 40]\n",
    "    \n",
    "    # For each sheet, add a heading and a table.\n",
    "    for sheet, rows in sheet_tables.items():\n",
    "        sheet_title = Paragraph(f\"<b>{sheet}</b>\", styles['Heading2'])\n",
    "        elements.append(sheet_title)\n",
    "        elements.append(Spacer(1, 6))\n",
    "        \n",
    "        table_data = [headers]\n",
    "        table_data.extend(rows)\n",
    "        \n",
    "        table = Table(table_data, colWidths=col_widths, repeatRows=1)\n",
    "        table.setStyle(TableStyle([\n",
    "            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, -1), 6),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, 0), 4),\n",
    "            ('TOPPADDING', (0, 0), (-1, 0), 4),\n",
    "            ('LEFTPADDING', (0, 0), (-1, -1), 2),\n",
    "            ('RIGHTPADDING', (0, 0), (-1, -1), 2),\n",
    "            ('GRID', (0, 0), (-1, -1), 0.5, colors.black),\n",
    "        ]))\n",
    "        \n",
    "        elements.append(table)\n",
    "        elements.append(Spacer(1, 12))\n",
    "    \n",
    "    # Add notes at the end of the PDF.\n",
    "    # note_text = (\"<para align='left'>\"\n",
    "    #              \"*Axis Maxlife NAV values are rounded off to 2 digits after decimal<br/>\"\n",
    "    #              \"*All returns are calculated as percentage(%)<br/>\"\n",
    "    #              # \"*All Daily returns for this report are 2-day return\"\n",
    "    #              # \"*Aditya Birla returns for this report is 4-day return\"\n",
    "    #              # \"*ICICI Prudential returns are not included in today's report due to a technical difficulty\"\n",
    "    #              \"</para>\")\n",
    "    note_paragraph = Paragraph(note_text, styles['Normal'])\n",
    "    elements.append(note_paragraph)\n",
    "    \n",
    "    doc.build(elements)\n",
    "    print(\"PDF report generated:\", output_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b02e43-8963-48ed-a2b7-02e93cfc146b",
   "metadata": {},
   "source": [
    "#### First uncomment the fund you want to exclude, comment all others\n",
    "#### If no fund is to be excluded, comment all the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ca5055-f9ac-44ae-b4ca-67169a2e3861",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_fund = [\n",
    "    # \"ICICI Prudential\",\n",
    "    # \"SBI Life\",\n",
    "    # \"Maxlife\",\n",
    "    # \"Bajaj Allianz\",\n",
    "    # \"LIC\",\n",
    "    # \"HDFC\",\n",
    "    # \"Aditya Birla\",\n",
    "    # \"Tata AIA\",\n",
    "    # \"PNB Metlife\",\n",
    "    # \"Kotak Mahindra\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e9c05d-dc99-4c19-8375-4b56d4180008",
   "metadata": {},
   "source": [
    "#### Text to write at the end of the report, uncomment and change lines as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25cc6a2f-91c1-44aa-9ddd-955f41c4b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_text = (\"<para align='left'>\"\n",
    "                 # \"*Axis Maxlife NAV values are rounded off to 2 digits after decimal<br/>\"\n",
    "                 \"*All returns are calculated as percentage(%)<br/>\"\n",
    "                 # \"*All Daily returns for this report are 2-day return\"\n",
    "                 # \"*Aditya Birla returns for this report is 4-day return\"\n",
    "                 # \"*ICICI Prudential returns are not included in today's report due to a technical difficulty\"\n",
    "                 \"</para>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd9306d-2f18-4dad-b088-dc8fbf211f96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFC Income Fund\n",
      "HDFC Bond Fund\n",
      "HDFC Pension Income Fund\n",
      "ICICI Prudential Income Fund\n",
      "ICICI Prudential Life Secure Fund\n",
      "Kotak Mahindra Kotak Dynamic Bond Fund\n",
      "Maxlife Secure Fund\n",
      "Aditya Birla Income Advantage Fund\n",
      "Tata AIA Wholelife Income Fund\n",
      "SBI Life Bond Fund\n",
      "SBI Life Bond Pension Fund II\n",
      "SBI Life Corporate Bond Fund\n",
      "Bajaj Allianz Bond Fund\n",
      "PNB Metlife Protector Fund II\n",
      "LIC Nivesh Plus Bond Fund\n",
      "ICICI Prudential Money Market Fund\n",
      "SBI Life Money Market Pension II\n",
      "ICICI Prudential Group Debt Fund II\n",
      "Kotak Mahindra Kotak Group Bond Fund\n",
      "PDF report generated: D:/Innover/09-May-2025_Insurance_Fund_Performance_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "# Part 3: Main Usage\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    excel_file_path = \"D:/Innover/Advanced_funds.xlsx\" # Update this path to your Excel file\n",
    "    exclude_fund.append(None)\n",
    "    sheets_datasets = process_excel_file(excel_file_path)\n",
    "    \n",
    "    date = (datetime.today() - timedelta(days=1)).strftime(\"%d-%b-%Y\")\n",
    "    output_pdf = f\"D:/Innover/{date}_Insurance_Fund_Performance_Report.pdf\"\n",
    "    \n",
    "    # output_pdf = f\"D:/Innover/spare.pdf\"\n",
    "    create_pdf_report(sheets_datasets, output_pdf, date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
